{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract frames\n",
    "Extract every 4 frames from video and save in dataset_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_frame(video, image_file):\n",
    "    cap = cv.VideoCapture(video)\n",
    "    idx_frame = 0\n",
    "    idx_save = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            if idx_frame % 4 == 0:\n",
    "                img = Image.fromarray(frame)\n",
    "                img.save(os.path.join(image_file, f'{idx_save}.jpg'))\n",
    "                idx_save +=1\n",
    "            idx_frame += 1\n",
    "        else:\n",
    "            break\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [10:07<00:00, 24.31s/it]\n"
     ]
    }
   ],
   "source": [
    "save_file = './dataset_frames'\n",
    "dataset = '../full_dataset'\n",
    "scenes = os.listdir(dataset)\n",
    "for scene in tqdm(scenes):\n",
    "    if not scene.startswith('.'):\n",
    "        cams = os.listdir(os.path.join(dataset,scene))\n",
    "        for cam in cams:\n",
    "            if not cam.startswith('.'):\n",
    "                video_path = os.path.join(dataset, scene, cam)\n",
    "                image_path = os.path.join(save_file, scene, os.path.splitext(cam)[0])\n",
    "                if not os.path.exists(image_path):\n",
    "                    os.makedirs(image_path)\n",
    "                save_frame(video_path, image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeling frames\n",
    "labeling clips with falling moment do not contains static laydown  \n",
    "each clip contains 9 frames if including end  \n",
    "save as python dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## human label for fall clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_clips_dict_train = {\n",
    "    'chute01/cam1':[(270,278)],\n",
    "    'chute01/cam2':[(270,278)],\n",
    "    'chute01/cam3':[(270,278)],\n",
    "    'chute01/cam4':[(270,278)],\n",
    "    'chute01/cam5':[(276,284)],\n",
    "    'chute01/cam6':[(270,278)],\n",
    "    'chute01/cam7':[(270,278)],\n",
    "    'chute01/cam8':[(270,278)],\n",
    "\n",
    "    'chute02/cam1':[(100,108)],\n",
    "    'chute02/cam2':[(103,111)],\n",
    "    'chute02/cam3':[(93,101)],\n",
    "    'chute02/cam4':[(93,101)],\n",
    "    'chute02/cam5':[(97,105)],\n",
    "    'chute02/cam6':[(102,110)],\n",
    "    'chute02/cam7':[(102,110)],\n",
    "    'chute02/cam8':[(96,104)],\n",
    "    \n",
    "    'chute03/cam1':[(151,159)],\n",
    "    'chute03/cam2':[(151,159)],\n",
    "    'chute03/cam3':[(151,159)],\n",
    "    'chute03/cam4':[(151,159)],\n",
    "    'chute03/cam5':[(157,165)],\n",
    "    'chute03/cam6':[(153,161)],\n",
    "    'chute03/cam7':[(153,161)],\n",
    "    'chute03/cam8':[(148,156)],\n",
    "    \n",
    "    'chute04/cam1':[(92,100),(167,175)],\n",
    "    'chute04/cam2':[(92,100),(167,175)],\n",
    "    'chute04/cam3':[(92,100),(170,178)],\n",
    "    'chute04/cam4':[(71,79),(149,157)],\n",
    "    'chute04/cam5':[(87,95),(166,174)],\n",
    "    'chute04/cam6':[(93,101),(170,178)],\n",
    "    'chute04/cam7':[(93,101),(169,177)],\n",
    "    'chute04/cam8':[(87,95),(163,171)],\n",
    "    \n",
    "    'chute05/cam1':[(82,90)],\n",
    "    'chute05/cam2':[(84,92)],\n",
    "    'chute05/cam3':[(79,87)],\n",
    "    'chute05/cam4':[(81,89)],\n",
    "    'chute05/cam5':[(82,90)],\n",
    "    'chute05/cam6':[(84,92)],\n",
    "    'chute05/cam7':[(84,92)],\n",
    "    'chute05/cam8':[(79,87)],\n",
    "    \n",
    "    'chute06/cam1':[(149,157)],\n",
    "    'chute06/cam2':[(174,182)],\n",
    "    'chute06/cam3':[(176,184)],\n",
    "    'chute06/cam4':[(172,180)],\n",
    "    'chute06/cam5':[(172,180)],\n",
    "    'chute06/cam6':[(175,183)],\n",
    "    'chute06/cam7':[(175,183)],\n",
    "    'chute06/cam8':[(174,182)],\n",
    "    \n",
    "    'chute07/cam1':[(127,135),(211,219)],\n",
    "    'chute07/cam2':[(124,132),(207,215)],\n",
    "    'chute07/cam3':[(125,133),(208,216)],\n",
    "    'chute07/cam4':[(121,129),(204,212)],\n",
    "    'chute07/cam5':[(121,129),(204,212)],\n",
    "    'chute07/cam6':[(125,133),(208,216)],\n",
    "    'chute07/cam7':[(123,131),(208,216)],\n",
    "    'chute07/cam8':[(125,133),(208,216)],\n",
    "    \n",
    "    'chute08/cam1':[(90,98)],\n",
    "    'chute08/cam2':[(88,96)],\n",
    "    'chute08/cam3':[(68,76)],\n",
    "    'chute08/cam4':[(88,96)],\n",
    "    'chute08/cam5':[(84,92)],\n",
    "    'chute08/cam6':[(88,96)],\n",
    "    'chute08/cam7':[(88,96)],\n",
    "    'chute08/cam8':[(83,91)],\n",
    "    \n",
    "    'chute09/cam1':[(160,168)],\n",
    "    'chute09/cam2':[(159,167)],\n",
    "    'chute09/cam3':[(157,165)],\n",
    "    'chute09/cam4':[(162,170)],\n",
    "    'chute09/cam5':[(160,168)],\n",
    "    'chute09/cam6':[(160,168)],\n",
    "    'chute09/cam7':[(160,168)],\n",
    "    'chute09/cam8':[(157,165)],\n",
    "    \n",
    "    'chute10/cam1':[(129,137)],\n",
    "    'chute10/cam2':[(129,137)],\n",
    "    'chute10/cam3':[(129,137)],\n",
    "    'chute10/cam4':[(134,142)],\n",
    "    'chute10/cam5':[(130,138)],\n",
    "    'chute10/cam6':[(130,138)],\n",
    "    'chute10/cam7':[(130,138)],\n",
    "    'chute10/cam8':[(129,137)],\n",
    "    \n",
    "    'chute11/cam1':[(121,129)],\n",
    "    'chute11/cam2':[(116,124)],\n",
    "    'chute11/cam3':[(121,129)],\n",
    "    'chute11/cam4':[(119,127)],\n",
    "    'chute11/cam5':[(116,124)],\n",
    "    'chute11/cam6':[(117,125)],\n",
    "    'chute11/cam7':[(117,125)],\n",
    "    'chute11/cam8':[(117,125)],\n",
    "    \n",
    "    'chute12/cam1':[(161,169)],\n",
    "    'chute12/cam2':[(157,165)],\n",
    "    'chute12/cam3':[(159,167)],\n",
    "    'chute12/cam4':[(159,167)],\n",
    "    'chute12/cam5':[(155,163)],\n",
    "    'chute12/cam6':[(155,163)],\n",
    "    'chute12/cam7':[(158,166)],\n",
    "    'chute12/cam8':[(158,166)],\n",
    "    \n",
    "    'chute13/cam1':[(113,121),(212,220)],\n",
    "    'chute13/cam2':[(218,226)],\n",
    "    'chute13/cam3':[(210,218)],\n",
    "    'chute13/cam4':[(113,121),(212,220)],\n",
    "    'chute13/cam5':[(118,126),(215,223)],\n",
    "    'chute13/cam6':[(118,126),(215,223)],\n",
    "    'chute13/cam7':[(118,126),(216,224)],\n",
    "    'chute13/cam8':[(118,126),(212,220)],\n",
    "    \n",
    "    'chute14/cam1':[(149,157),(260,268)],\n",
    "    'chute14/cam2':[(257,265)],\n",
    "    'chute14/cam3':[(258,266)],\n",
    "    'chute14/cam5':[(145,153),(257,265)],\n",
    "    'chute14/cam6':[(145,153),(257,265)],\n",
    "    'chute14/cam7':[(140,148),(249,257)],\n",
    "    'chute14/cam8':[(143,151),(252,260)],\n",
    "    \n",
    "    'chute15/cam1':[(128,136),(193,201)],\n",
    "    'chute15/cam2':[(128,136),(193,201)],\n",
    "    'chute15/cam3':[(128,136),(193,201)],\n",
    "    'chute15/cam4':[(128,136),(193,201)],\n",
    "    'chute15/cam5':[(132,140),(196,204)],\n",
    "    'chute15/cam6':[(132,140),(198,206)],\n",
    "    'chute15/cam7':[(129,137),(193,201)],\n",
    "    'chute15/cam8':[(125,133),(188,196)],\n",
    "    \n",
    "    'chute16/cam1':[(228,236)],\n",
    "    'chute16/cam2':[(228,236)],\n",
    "    'chute16/cam3':[(225,233)],\n",
    "    'chute16/cam4':[(223,231)],\n",
    "    'chute16/cam5':[(226,234)],\n",
    "    'chute16/cam6':[(224,232)],\n",
    "    'chute16/cam7':[(224,232)],\n",
    "    'chute16/cam8':[(224,232)],\n",
    "    \n",
    "    'chute17/cam1':[(185,193)],\n",
    "    'chute17/cam2':[(185,193)],\n",
    "    'chute17/cam3':[(185,193)],\n",
    "    'chute17/cam4':[(183,191)],\n",
    "    'chute17/cam5':[(181,189)],\n",
    "    'chute17/cam6':[(181,189)],\n",
    "    'chute17/cam7':[(187,195)],\n",
    "    'chute17/cam8':[(186,194)],\n",
    "    \n",
    "    'chute18/cam1':[(167,175)],\n",
    "    'chute18/cam2':[(169,177)],\n",
    "    'chute18/cam3':[(164,172)],\n",
    "    'chute18/cam4':[(143,151)],\n",
    "    'chute18/cam5':[(163,171)],\n",
    "    'chute18/cam6':[(170,178)],\n",
    "    'chute18/cam7':[(170,178)],\n",
    "    'chute18/cam8':[(163,171)],\n",
    "    \n",
    "    'chute19/cam1':[(132,140)],\n",
    "    'chute19/cam2':[(132,140)],\n",
    "    'chute19/cam3':[(132,140)],\n",
    "    'chute19/cam4':[(132,140)],\n",
    "    'chute19/cam5':[(126,134)],\n",
    "    'chute19/cam6':[(133,141)],\n",
    "    'chute19/cam7':[(126,134)],\n",
    "    'chute19/cam8':[(132,140)],\n",
    "    \n",
    "    'chute20/cam1':[(144,152),(164,172)],\n",
    "    'chute20/cam2':[(139,147),(161,169)],\n",
    "    'chute20/cam3':[(139,147),(161,169)],\n",
    "    'chute20/cam4':[(140,148),(161,169)],\n",
    "    'chute20/cam5':[(140,148),(161,169)],\n",
    "    'chute20/cam6':[(140,148),(161,169)],\n",
    "    'chute20/cam7':[(140,148),(161,169)],\n",
    "    'chute20/cam8':[(140,148),(161,169)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fall_label_for_train.json', 'w') as file:\n",
    "    json.dump(fall_clips_dict_train, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_clips_dict_test = {\n",
    "    'chute21/cam1':[(223,231)],\n",
    "    'chute21/cam2':[(226,234)],\n",
    "    'chute21/cam3':[(226,234)],\n",
    "    'chute21/cam4':[(218,226)],\n",
    "    'chute21/cam5':[(218,226)],\n",
    "    'chute21/cam6':[(227,235)],\n",
    "    'chute21/cam7':[(227,235)],\n",
    "    'chute21/cam8':[(219,227)],\n",
    "    \n",
    "    'chute22/cam1':[(193,201)],\n",
    "    'chute22/cam2':[(203,211)],\n",
    "    'chute22/cam3':[(207,215)],\n",
    "    'chute22/cam4':[(207,215)],\n",
    "    'chute22/cam5':[(207,215)],\n",
    "    'chute22/cam6':[(205,213)],\n",
    "    'chute22/cam7':[(205,213)],\n",
    "    'chute22/cam8':[(204,212)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fall_label_for_test.json', 'w') as file:\n",
    "    json.dump(fall_clips_dict_test, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute not fall clip\n",
    "50 frames before fall clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_fall_clips_dict_train = copy.deepcopy(fall_clips_dict_train)\n",
    "not_fall_clips_dict_train['chute20/cam1'] = [(144,152)]\n",
    "not_fall_clips_dict_train['chute20/cam2'] = [(139,147)]\n",
    "not_fall_clips_dict_train['chute20/cam3'] = [(139,147)]\n",
    "not_fall_clips_dict_train['chute20/cam4'] = [(140,148)]\n",
    "not_fall_clips_dict_train['chute20/cam5'] = [(140,148)]\n",
    "not_fall_clips_dict_train['chute20/cam6'] = [(140,148)]\n",
    "not_fall_clips_dict_train['chute20/cam7'] = [(140,148)]\n",
    "not_fall_clips_dict_train['chute20/cam8'] = [(140,148)]\n",
    "for scene, expands in not_fall_clips_dict_train.items():\n",
    "    for idx in range(len(expands)):\n",
    "        expands[idx] = (expands[idx][0]-60, expands[idx][1]-18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('not_fall_label_for_train.json', 'w') as file:\n",
    "    json.dump(not_fall_clips_dict_train, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_fall_clips_dict_test = copy.deepcopy(fall_clips_dict_test)\n",
    "for scene, expands in not_fall_clips_dict_test.items():\n",
    "    for idx in range(len(expands)):\n",
    "        expands[idx] = (expands[idx][0]-60, expands[idx][1]-18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('not_fall_label_for_test.json', 'w') as file:\n",
    "    json.dump(not_fall_clips_dict_test, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the correctness of label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './dataset_frames'\n",
    "for scene, expands in fall_clips_dict_test.items():\n",
    "    for expand in expands:\n",
    "        if expand[1]-expand[0] != 8:\n",
    "            print(scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate img data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_img_seq(img_dir, start, end, save_dir):\n",
    "    trans = transforms.Compose([transforms.CenterCrop(480),transforms.Resize(224)])\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    for idx in range(start, end):\n",
    "        img = Image.open(os.path.join(img_dir,f'{idx}.jpg'))\n",
    "        img = trans(img)\n",
    "        img.save(os.path.join(save_dir,f'{idx}.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159/159 [01:17<00:00,  2.05it/s]\n"
     ]
    }
   ],
   "source": [
    "img_folder = './dataset_frames'\n",
    "save_folder = './not_fall_img_train'\n",
    "\n",
    "for scene, expands in tqdm(not_fall_clips_dict_train.items()):\n",
    "    img_dir = os.path.join(img_folder, scene)\n",
    "    save_dir = os.path.join(save_folder, scene)\n",
    "    for expand in expands:\n",
    "        save_img_seq(img_dir, *expand, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_list(data_dir, frame_dict):\n",
    "    img_names = []\n",
    "    for scene, expands in frame_dict.items():\n",
    "        for cam in os.listdir(os.path.join(data_dir, scene)):\n",
    "            if not cam.startswith('.'):\n",
    "                img_dir = os.path.join(data_dir,scene,cam)\n",
    "                for expand in expands:\n",
    "                    for img_idx in range(*expand):\n",
    "                        img_name = os.path.join(img_dir,f'{img_idx}.jpg')\n",
    "                        img_names.append(img_name)\n",
    "    return img_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './dataset_frames'\n",
    "# get frame for fall and not fall\n",
    "train_f_img = get_frame_list(data_dir, trainset_fall)\n",
    "train_f_lbl = list(np.ones(len(train_f_img)))\n",
    "train_n_img = get_frame_list(data_dir, trainset_not_fall)\n",
    "train_n_lbl = list(np.zeros(len(train_n_img)))\n",
    "# mix fall and not fall and save\n",
    "train_f_img.extend(train_n_img)\n",
    "train_f_lbl.extend(train_n_lbl)\n",
    "train_pd = pd.DataFrame({'img':train_f_img, 'label':train_f_lbl})\n",
    "train_pd.to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get frame for fall and not fall\n",
    "test_f_img = get_frame_list(data_dir, testset_fall)\n",
    "test_f_lbl = list(np.ones(len(test_f_img)))\n",
    "test_n_img = get_frame_list(data_dir, testset_not_fall)\n",
    "test_n_lbl = list(np.zeros(len(test_n_img)))\n",
    "# mix fall and not fall and save\n",
    "test_f_img.extend(test_n_img)\n",
    "test_f_lbl.extend(test_n_lbl)\n",
    "test_pd = pd.DataFrame({'img':test_f_img, 'label':test_f_lbl})\n",
    "test_pd.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:scipy_test]",
   "language": "python",
   "name": "conda-env-scipy_test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
