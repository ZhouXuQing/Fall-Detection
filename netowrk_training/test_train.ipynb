{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "on epoch 0:   0%|          | 0/13696 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "reduce failed to synchronize: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ab2e05fc3709>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_los\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-ab2e05fc3709>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, trainloader, testloader, func_los, func_acc, total_epoch, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch_num\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0m_train_los\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_train_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_los\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0m_test_los\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_test_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_los\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-ab2e05fc3709>\u001b[0m in \u001b[0;36mone_epoch\u001b[0;34m(epoch_num, model, dataloader, func_los, func_acc, optimizer, update_param)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mbatch_los\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_los\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;31m# acc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mbatch_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/getting_start_env/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/getting_start_env/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/getting_start_env/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2112\u001b[0m     return torch._C._nn.binary_cross_entropy(\n\u001b[0;32m-> 2113\u001b[0;31m         input, target, weight, reduction_enum)\n\u001b[0m\u001b[1;32m   2114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: reduce failed to synchronize: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "\n",
    "def one_epoch(epoch_num, model, dataloader, func_los, func_acc, optimizer, update_param):\n",
    "    # if update_param = True, train network, otherwise do not update network parameters\n",
    "    \n",
    "    dataloader = tqdm(dataloader, desc = f'on epoch {epoch_num}')\n",
    "    total_los = 0.0; total_acc = 0.0\n",
    "    \n",
    "    for data in dataloader:\n",
    "        image = data[0].cuda()\n",
    "        label = data[1].cuda()\n",
    "        # los\n",
    "        if update_param:\n",
    "            model.train() # set net in training mode\n",
    "            optimizer.zero_grad()\n",
    "            output = model(image)\n",
    "            batch_los = func_los(output, label)\n",
    "            batch_los.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            model.eval()\n",
    "            output = model(image)\n",
    "            batch_los = func_los(output, label)\n",
    "        # acc\n",
    "        batch_acc = func_acc(output, label)\n",
    "        # accumulate\n",
    "        total_los += batch_los.item()\n",
    "        total_acc += batch_acc.item()\n",
    "        \n",
    "    avg_los = total_los/len(dataloader)\n",
    "    avg_acc = total_acc/len(dataloader)\n",
    "    print(f'los={avg_los}; acc={avg_acc}')\n",
    "    return avg_los, avg_acc\n",
    "\n",
    "\n",
    "def save_checkpoint(epoch_num, train_los, test_los, train_acc, test_acc, model):\n",
    "    torch.save(model.state_dict(), f'./train_result/model_on_epoch{epoch_num}.pkl')\n",
    "    history = {'train_los': train_los,\n",
    "               'test_los': test_los,\n",
    "               'train_acc': train_acc,\n",
    "               'test_acc': test_acc\n",
    "              }\n",
    "    with open('./train_result/history.json','w') as file:\n",
    "        json.dump(history, file)\n",
    "        \n",
    "\n",
    "def train(model, trainloader, testloader, func_los, func_acc, total_epoch, optimizer, scheduler):\n",
    "    train_los = []\n",
    "    test_los = []\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    \n",
    "    for epoch_num in range(total_epoch):\n",
    "        if epoch_num == 0:\n",
    "            _train_los, _train_acc = one_epoch(epoch_num, model, trainloader, func_los, func_acc, optimizer, update_param = False)\n",
    "            _test_los, _test_acc = one_epoch(epoch_num, model, testloader, func_los, func_acc, optimizer, update_param = False)\n",
    "        else:\n",
    "            _train_los, _train_acc = one_epoch(epoch_num, model, trainloader, func_los, func_acc, optimizer, update_param = True)\n",
    "            _test_los, _test_acc = one_epoch(epoch_num, model, testloader, func_los, func_acc, optimizer, update_param = False)\n",
    "        scheduler.step()\n",
    "        \n",
    "        train_los.append(_train_los)\n",
    "        test_los.append(_test_los)\n",
    "        train_acc.append(_train_acc)\n",
    "        test_acc.append(_test_acc)\n",
    "        \n",
    "        if (epoch_num % 5 == 0) or (epoch_num == total_epoch-1):\n",
    "            save_checkpoint(epoch_num, train_los, test_los, train_acc, test_acc, model)\n",
    "            \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from dataset import FallDataset\n",
    "    from model import binary_resnet50\n",
    "    from loss import BinaryHitRate\n",
    "\n",
    "    # DataSet\n",
    "    trainset = FallDataset('./train.csv')\n",
    "    trainloader = DataLoader(trainset, batch_size=1, shuffle=True, num_workers = 8)\n",
    "\n",
    "    testset = FallDataset('./test.csv')\n",
    "    testloader = DataLoader(testset, batch_size=1, shuffle=True, num_workers = 8)\n",
    "\n",
    "    # Model, Loss, Eval\n",
    "    model = binary_resnet50().cuda()\n",
    "    \n",
    "    func_los = torch.nn.BCELoss()\n",
    "    func_acc = BinaryHitRate()\n",
    "\n",
    "    # Train Config\n",
    "    total_epoch = 100\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = 0.1, momentum = 0.9)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[round(total_epoch/2),round(total_epoch*3/4)], gamma=0.1)\n",
    "\n",
    "    # Start training \n",
    "    train(model, trainloader, testloader, func_los, func_acc, total_epoch, optimizer, scheduler)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:getting_start_env]",
   "language": "python",
   "name": "conda-env-getting_start_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
